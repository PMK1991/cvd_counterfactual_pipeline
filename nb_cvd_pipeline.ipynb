{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import make_scorer, f1_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import dice_ml\n",
    "from dice_ml.utils import helpers # helper functions\n",
    "from dice_ml import Data,Model,Dice\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "import time\n",
    "import threading\n",
    "from joblib import Parallel, delayed\n",
    "import os\n",
    "import numpy as np\n",
    "from dataLoader import DataLoader\n",
    "from plotter import Plotter\n",
    "from hyperParameterTuning import HyperparameterTuner\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully.\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Best Parameters: {'classifier__colsample_bytree': 1.0, 'classifier__learning_rate': 0.01, 'classifier__max_depth': 3, 'classifier__n_estimators': 300, 'classifier__subsample': 0.8}\n",
      "Best Score: 0.8564724269401216\n",
      "Best Estimator: Pipeline(steps=[('preprocessor',\n",
      "                 ColumnTransformer(transformers=[('num',\n",
      "                                                  Pipeline(steps=[('scaler',\n",
      "                                                                   StandardScaler())]),\n",
      "                                                  ['age', 'trestbps', 'chol',\n",
      "                                                   'thalach', 'oldpeak']),\n",
      "                                                 ('cat',\n",
      "                                                  Pipeline(steps=[('onehot',\n",
      "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
      "                                                  Index(['cp', 'exang', 'fbs', 'restecg', 'sex', 'slope'], dtype='object'))])),\n",
      "                ('classifier',\n",
      "                 XGBClassifier(base_score=N...\n",
      "                               feature_types=None, gamma=None, grow_policy=None,\n",
      "                               importance_type=None,\n",
      "                               interaction_constraints=None, learning_rate=0.01,\n",
      "                               max_bin=None, max_cat_threshold=None,\n",
      "                               max_cat_to_onehot=None, max_delta_step=None,\n",
      "                               max_depth=3, max_leaves=None,\n",
      "                               min_child_weight=None, missing=nan,\n",
      "                               monotone_constraints=None, multi_strategy=None,\n",
      "                               n_estimators=300, n_jobs=None,\n",
      "                               num_parallel_tree=None, random_state=None, ...))])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load dataset using DataLoader\n",
    "dataLoader = DataLoader(\"heart_statlog_cleveland_hungary_final.csv\")\n",
    "df_cvd = dataLoader.load_data()\n",
    "'''if df_cvd is not None:\n",
    "    df_cvd = dataLoader.remove_outliers_iqr(df_cvd)'''\n",
    "\n",
    "# Assuming the target column is named 'target'\n",
    "X = df_cvd.drop(columns='target')\n",
    "y = df_cvd['target']\n",
    "\n",
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "numerical = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "\n",
    "categorical = X_train.columns.difference(numerical)\n",
    "\n",
    "\n",
    "# We create the preprocessing pipelines for both numeric and categorical data.\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "transformations = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numerical),\n",
    "        ('cat', categorical_transformer, categorical)])\n",
    "\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "('preprocessor', transformations),\n",
    "('classifier', XGBClassifier())\n",
    "])\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [100, 200, 300],\n",
    "    'classifier__max_depth': [3, 6, 9],\n",
    "    'classifier__learning_rate': [0.01, 0.1, 0.2],\n",
    "    'classifier__subsample': [0.8, 1.0],\n",
    "    'classifier__colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Create the HyperparameterTuner instance\n",
    "tuner = HyperparameterTuner(pipeline, param_grid)\n",
    "\n",
    "# Perform hyperparameter tuning\n",
    "best_params, best_score = tuner.tune(X_train, y_train)\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)\n",
    "\n",
    "# Get the best estimator\n",
    "best_model = tuner.get_best_estimator()\n",
    "print(\"Best Estimator:\", best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9066666666666666\n",
      "Test F1 Score: 0.9067330842673308\n",
      "Test Precision: 0.908088888888889\n",
      "Test Recall: 0.9066666666666666\n"
     ]
    }
   ],
   "source": [
    "# Train the model with the best hyperparameters on the full training set\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "print(f\"Test F1 Score: {f1}\")\n",
    "print(f\"Test Precision: {precision}\")\n",
    "print(f\"Test Recall: {recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "numerical = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "\n",
    "categorical = X_train.columns.difference(numerical)\n",
    "\n",
    "\n",
    "# We create the preprocessing pipelines for both numeric and categorical data.\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "transformations = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numerical),\n",
    "        ('cat', categorical_transformer, categorical)])\n",
    "\n",
    "\n",
    "pipeline = Pipeline(steps=[('preprocessor', transformations),('classifier', XGBClassifier(max_depth=3, learning_rate=0.01, n_estimators=300, subsample=0.8,colsample_bytree=1.0))])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model on the entire training set\n",
    "xgb_pipeline = pipeline.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = xgb_pipeline.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_high_risk_tp = X_test[(y_pred == 1) & (y_test == 1)].reset_index().drop(['index'], axis=1)\n",
    "#X_high_risk_tp = X_test[(y_pred == 1) & (y_test == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "\n",
    "# Create a DICE data object\n",
    "d = Data(dataframe=pd.DataFrame(train_data, columns=df_cvd.columns), continuous_features=['age', 'trestbps', 'chol', 'thalach', 'oldpeak'],outcome_name='target')\n",
    "\n",
    "# Create a DICE model object\n",
    "m = Model(model=pipeline, backend=\"sklearn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import queue\n",
    "\n",
    "\n",
    "\n",
    "def generate_cf_general(test_instance, timeout=30):\n",
    "    q = queue.Queue()\n",
    "\n",
    "    def target():\n",
    "        try:\n",
    "            result = Dice(d, m, method='genetic').generate_counterfactuals(test_instance, total_CFs=20, desired_class=\"opposite\",\n",
    "                                                                           features_to_vary=[\"trestbps\", \"chol\"],\n",
    "                                                                           #diversity_weight=5, proximity_weight=2, sparsity_weight=5\n",
    "                                                                          )\n",
    "            q.put(result)\n",
    "        except Exception as e:\n",
    "            print(\"No counterfactuals found for test instance:\", test_instance)\n",
    "            #df_no_counterfactuals.append(test_instance)\n",
    "            q.put(None)\n",
    "\n",
    "    # Start a new thread to run the target function\n",
    "    thread = threading.Thread(target=target)\n",
    "    thread.start()\n",
    "\n",
    "    # Wait for the thread to finish or raise a timeout exception\n",
    "    thread.join(timeout)\n",
    "\n",
    "    if thread.is_alive():\n",
    "        # The thread is still running, so raise a timeout exception\n",
    "        print(\"No counterfactuals found for test instance-timed out:\", test_instance)\n",
    "        #df_no_counterfactuals.append(test_instance)\n",
    "        q.put(None)\n",
    "    else:\n",
    "        # The thread has finished, so return the result\n",
    "        return q.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "exps_general= []\n",
    "num_cores = -1\n",
    "df_no_counterfactuals_general= pd.DataFrame(columns=X_high_risk_tp.columns)\n",
    "# Iterate over each instance of X_high_risk and generate counterfactuals\n",
    "for i in range(len(X_high_risk_tp)):\n",
    "    test_instance = X_high_risk_tp.iloc[[i]]\n",
    "    print(i)   \n",
    "    exp = Parallel(n_jobs=num_cores)(delayed(generate_cf_general)(test_instance) for i in range(1))\n",
    "    exps_general.append(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exps_general[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of None values in exps_general: 46\n"
     ]
    }
   ],
   "source": [
    "num_none = sum(exp[0] is None for exp in exps_general)\n",
    "print(\"Number of None values in exps_general:\", num_none)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_instance = X_high_risk_tp.iloc[0:1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cf_df = exps_general[0].cf_examples_list[0]  # Remove one level of indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cf_df = exps_general[0][0].cf_examples_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>136</td>\n",
       "      <td>203</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope\n",
       "0   58    1   4       136   203    1        0      123      1      1.2      2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'query_instance' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Extract the original instance values for comparison\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m original_values \u001b[38;5;241m=\u001b[39m \u001b[43mquery_instance\u001b[49m[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchol\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrestbps\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Find the changes in 'chol' and 'trestbps'\u001b[39;00m\n\u001b[0;32m      5\u001b[0m changes \u001b[38;5;241m=\u001b[39m cf_df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchol\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrestbps\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row: row \u001b[38;5;241m!=\u001b[39m original_values, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'query_instance' is not defined"
     ]
    }
   ],
   "source": [
    "# Extract the original instance values for comparison\n",
    "original_values = query_instance[['chol', 'trestbps']].values[0]\n",
    "\n",
    "# Find the changes in 'chol' and 'trestbps'\n",
    "changes = cf_df[['chol', 'trestbps']].apply(lambda row: row != original_values, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'CounterfactualExamples' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mcf_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mchol\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrestbps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'CounterfactualExamples' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "cf_df[['chol', 'trestbps']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
