{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import dice_ml\n",
    "from dice_ml.utils import helpers # helper functions\n",
    "from dice_ml import Data,Model,Dice\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "import time\n",
    "import threading\n",
    "from joblib import Parallel, delayed\n",
    "#from langchain_experimental.agents import create_pandas_dataframe_agent\n",
    "import os\n",
    "import json\n",
    "import openai\n",
    "from openai import AzureOpenAI\n",
    "#from langchain.llms import AzureOpenAI\n",
    "#from langchain_openai import AzureChatOpenAI\n",
    "import pandas as pd \n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "xgb.set_config(verbosity=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_heart_disease = pd.read_csv(\"heart_statlog_cleveland_hungary_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_heart_disease =  dataframe_heart_disease.dropna()\n",
    "dataframe_heart_disease =  dataframe_heart_disease.drop_duplicates()\n",
    "dataframe_heart_disease = dataframe_heart_disease[dataframe_heart_disease['chol'] !=0]\n",
    "dataframe_heart_disease = dataframe_heart_disease[dataframe_heart_disease['trestbps'] !=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features and target label\n",
    "y = dataframe_heart_disease.target\n",
    "X = dataframe_heart_disease.drop(['target'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "\n",
    "categorical = X_train.columns.difference(numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create the preprocessing pipelines for both numeric and categorical data.\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "transformations = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numerical),\n",
    "        ('cat', categorical_transformer, categorical)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append classifier to preprocessing pipeline.\n",
    "# Now we have a full prediction pipeline.\n",
    "clf = Pipeline(steps=[('preprocessor', transformations),\n",
    "                      ('classifier', XGBClassifier())])\n",
    "xgb_model = clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the pipeline with the XGBClassifier\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', transformations),\n",
    "    ('classifier', XGBClassifier(max_depth=5, learning_rate=0.5, n_estimators=200, gamma=0))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model on the entire training set\n",
    "xgb_pipeline = pipeline.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = xgb_pipeline.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_high_risk_tp = X_test[(y_pred == 1) & (y_test == 1)].reset_index().drop(['index'], axis=1)\n",
    "#X_high_risk_tp = X_test[(y_pred == 1) & (y_test == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "\n",
    "# Create a DICE data object\n",
    "d = Data(dataframe=pd.DataFrame(train_data, columns=dataframe_heart_disease.columns), continuous_features=['age', 'trestbps', 'chol', 'thalach', 'oldpeak'],outcome_name='target')\n",
    "\n",
    "# Create a DICE model object\n",
    "m = Model(model=xgb_pipeline, backend=\"sklearn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideal Constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import queue\n",
    "\n",
    "df_no_counterfactuals = pd.DataFrame(columns=X_high_risk_tp.columns)\n",
    "def generate_cf(test_instance, timeout=10):\n",
    "    q = queue.Queue()\n",
    "\n",
    "    def target():\n",
    "        try:\n",
    "            result = Dice(d, m, method='genetic').generate_counterfactuals(test_instance, total_CFs=20, desired_class=\"opposite\",\n",
    "                                                                           features_to_vary=[\"trestbps\", \"chol\", \"fbs\"],\n",
    "                                                                           diversity_weight=5, proximity_weight=2, sparsity_weight=5,\n",
    "                                                                           permitted_range={ \"chol\": [100, 200], \"trestbps\": [100, 120] }\n",
    "                                                                           )\n",
    "            q.put(result)\n",
    "        except Exception as e:\n",
    "            print(\"No counterfactuals found for test instance:\", test_instance)\n",
    "            df_no_counterfactuals.append(test_instance)\n",
    "            q.put(None)\n",
    "\n",
    "    # Start a new thread to run the target function\n",
    "    thread = threading.Thread(target=target)\n",
    "    thread.start()\n",
    "\n",
    "    # Wait for the thread to finish or raise a timeout exception\n",
    "    thread.join(timeout)\n",
    "\n",
    "    if thread.is_alive():\n",
    "        # The thread is still running, so raise a timeout exception\n",
    "        print(\"No counterfactuals found for test instance-timed out:\", test_instance)\n",
    "        df_no_counterfactuals.append(test_instance)\n",
    "        q.put(None)\n",
    "    else:\n",
    "        # The thread has finished, so return the result\n",
    "        return q.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "exps_ideal = []\n",
    "num_cores = -1\n",
    "\n",
    "# Iterate over each instance of X_high_risk and generate counterfactuals\n",
    "for i in range(len(X_high_risk_tp)):\n",
    "    test_instance = X_high_risk_tp.iloc[[i]]\n",
    "    print(i)\n",
    "    exp = Parallel(n_jobs=num_cores)(delayed(generate_cf)(test_instance) for i in range(1))\n",
    "    exps_ideal.append(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validity_list = []\n",
    "for exps in exps_ideal:\n",
    "    \n",
    "    if exps[0] is not None:\n",
    "       exp_df = exps[0].cf_examples_list[0].final_cfs_df\n",
    "       validity_list.append(xgb_pipeline.predict(exp_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Flatten the nested array\n",
    "flattened_array = [item for sublist in validity_list for item in sublist]\n",
    "\n",
    "# Calculate the sum of 1s\n",
    "sum_of_ones = sum(item == 1 for item in flattened_array)\n",
    "\n",
    "print(\"Flattened Array:\", flattened_array)\n",
    "print(\"Sum of 1s:\", sum_of_ones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feasible Constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import queue\n",
    "\n",
    "df_no_counterfactuals = pd.DataFrame(columns=X_high_risk_tp.columns)\n",
    "def generate_cf_feasible(test_instance, timeout=30):\n",
    "    q = queue.Queue()\n",
    "\n",
    "    def target():\n",
    "        try:\n",
    "            result = Dice(d, m, method='genetic').generate_counterfactuals(test_instance, total_CFs=20, desired_class=\"opposite\",\n",
    "                                                                           features_to_vary=[\"trestbps\", \"chol\", \"fbs\"],\n",
    "                                                                           #diversity_weight=5, proximity_weight=2, sparsity_weight=5,\n",
    "                                                                           permitted_range={\"trestbps\": [80, test_instance['trestbps'].values[0]-10],\n",
    "                                                                                            \"chol\": [100, test_instance['chol'].values[0]-0.1*test_instance['chol'].values[0]],\n",
    "                                                                                           }\n",
    "                                                                           )\n",
    "            q.put(result)\n",
    "        except Exception as e:\n",
    "            print(\"No counterfactuals found for test instance:\", test_instance)\n",
    "            df_no_counterfactuals.append(test_instance)\n",
    "            q.put(None)\n",
    "\n",
    "    # Start a new thread to run the target function\n",
    "    thread = threading.Thread(target=target)\n",
    "    thread.start()\n",
    "\n",
    "    # Wait for the thread to finish or raise a timeout exception\n",
    "    thread.join(timeout)\n",
    "\n",
    "    if thread.is_alive():\n",
    "        # The thread is still running, so raise a timeout exception\n",
    "        print(\"No counterfactuals found for test instance-timed out:\", test_instance)\n",
    "        df_no_counterfactuals.append(test_instance)\n",
    "        q.put(None)\n",
    "    else:\n",
    "        # The thread has finished, so return the result\n",
    "        return q.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "exps_feasible = []\n",
    "num_cores = -1\n",
    "\n",
    "# Iterate over each instance of X_high_risk and generate counterfactuals\n",
    "for i in range(len(X_high_risk_tp)):\n",
    "    test_instance = X_high_risk_tp.iloc[[i]]\n",
    "    print(i)\n",
    "    exp = Parallel(n_jobs=num_cores)(delayed(generate_cf_feasible)(test_instance) for i in range(1))\n",
    "    exps_feasible.append(exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General Counterfactuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import queue\n",
    "\n",
    "df_no_counterfactuals = pd.DataFrame(columns=X_high_risk_tp.columns)\n",
    "def generate_cf_feasible_(test_instance, timeout=30):\n",
    "    q = queue.Queue()\n",
    "\n",
    "    def target():\n",
    "        try:\n",
    "            result = Dice(d, m, method='genetic').generate_counterfactuals(test_instance, total_CFs=20, desired_class=\"opposite\",\n",
    "                                                                           features_to_vary=[\"trestbps\", \"chol\", \"thalach\"],\n",
    "                                                                           #diversity_weight=5, proximity_weight=2, sparsity_weight=5,\n",
    "                                                                           #permitted_range={\"trestbps\": [80, test_instance['trestbps'].values[0]-1],\n",
    "                                                                           #                 \"chol\": [100, test_instance['chol'].values[0]-1],\n",
    "                                                                           #                 \"thalach\": [test_instance['thalach'].values[0]+1, 220 - test_instance['age'].values[0]]}\n",
    "                                                                           )\n",
    "            q.put(result)\n",
    "        except Exception as e:\n",
    "            print(\"No counterfactuals found for test instance:\", test_instance)\n",
    "            df_no_counterfactuals.append(test_instance)\n",
    "            q.put(None)\n",
    "\n",
    "    # Start a new thread to run the target function\n",
    "    thread = threading.Thread(target=target)\n",
    "    thread.start()\n",
    "\n",
    "    # Wait for the thread to finish or raise a timeout exception\n",
    "    thread.join(timeout)\n",
    "\n",
    "    if thread.is_alive():\n",
    "        # The thread is still running, so raise a timeout exception\n",
    "        print(\"No counterfactuals found for test instance-timed out:\", test_instance)\n",
    "        df_no_counterfactuals.append(test_instance)\n",
    "        q.put(None)\n",
    "    else:\n",
    "        # The thread has finished, so return the result\n",
    "        return q.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "exps_feasible_ = []\n",
    "num_cores = -1\n",
    "\n",
    "# Iterate over each instance of X_high_risk and generate counterfactuals\n",
    "for i in range(len(X_high_risk_tp)):\n",
    "    test_instance = X_high_risk_tp.iloc[[i]]\n",
    "    print(i)\n",
    "    exp = Parallel(n_jobs=num_cores)(delayed(generate_cf_feasible_)(test_instance) for i in range(1))\n",
    "    exps_feasible_.append(exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Structural Causal Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"heart_statlog_cleveland_hungary_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_oldpeak(oldpeak):\n",
    "    if oldpeak <= 1:\n",
    "        return 0\n",
    "    elif oldpeak > 1 and oldpeak <= 2:\n",
    "        return 1\n",
    "    elif oldpeak > 2 and oldpeak <= 3:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['oldpeak'] = df['oldpeak'].apply(bin_oldpeak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =  df.dropna()\n",
    "df = df[df['chol'] >0]\n",
    "df = df[df['trestbps'] >0]\n",
    "#df = df[df['oldpeak'] >=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a directed graph\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Define the three layers: Risk Factors, Diseases, Symptoms\n",
    "risk_factors = ['age', 'sex', 'chol', 'fbs', 'trestbps']\n",
    "diseases = ['target']  # Heart disease\n",
    "symptoms = ['cp', 'restecg', 'thalach', 'exang', 'slope','oldpeak']\n",
    "\n",
    "# Add causal relationships: Risk Factors -> Diseases\n",
    "for rf in risk_factors:\n",
    "    G.add_edge(rf, 'target')\n",
    "\n",
    "# Add causal relationships: Diseases -> Symptoms\n",
    "for sym in symptoms:\n",
    "    G.add_edge('target', sym)\n",
    "\n",
    "# Add some direct Risk Factors -> Symptoms relationships\n",
    "#G.add_edge('age', 'cp')\n",
    "G.add_edge('age', 'chol')\n",
    "G.add_edge('age', 'trestbps')\n",
    "G.add_edge('sex', 'trestbps')\n",
    "G.add_edge('sex', 'chol')\n",
    "G.add_edge('chol', 'trestbps')\n",
    "G.add_edge('thalach', 'exang')\n",
    "G.add_edge('exang', 'cp')\n",
    "#G.add_edge('fbs', 'oldpeak')\n",
    "\n",
    "# Use shell_layout for a circular arrangement of nodes\n",
    "plt.figure(figsize=(12, 10))\n",
    "pos = nx.shell_layout(G, nlist=[risk_factors, diseases, symptoms])\n",
    "\n",
    "# Draw the graph with shell layout\n",
    "nx.draw(G, pos, with_labels=True, node_size=3000, node_color='lightcoral', font_size=10, font_weight='bold', arrowsize=20)\n",
    "\n",
    "# Display the graph\n",
    "plt.title('Causal DAG for Cardiovascular Disease (CVD)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'] = df['target'].astype('category')\n",
    "df['exang'] = df['exang'].astype('category')\n",
    "df['fbs'] = df['fbs'].astype('category')\n",
    "df['cp'] = df['cp'].astype('category')\n",
    "df['restecg'] = df['restecg'].astype('category')\n",
    "df['slope'] = df['slope'].astype('category')\n",
    "df['sex'] = df['sex'].astype('category')\n",
    "df['oldpeak'] = df['oldpeak'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dowhy import gcm\n",
    "causal_model = gcm.InvertibleStructuralCausalModel(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcm.auto.assign_causal_mechanisms(causal_model, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcm.fit(causal_model, df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcm.evaluate_causal_model(causal_model, df)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_high_risk_tp = X_high_risk_tp.assign(target=1)\n",
    "df_high_risk_tp = X_high_risk_tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_high_risk_tp.to_csv(\"df_high_risk_tp.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_high_risk_tp[3:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_high_risk_tp)):\n",
    "    df_risk = df_high_risk_tp.iloc[[i]]\n",
    "    # Apply the filtering conditions\n",
    "    age = df_risk['age']\n",
    "    chol_risk = df_risk['chol']\n",
    "    trestbps_risk = df_risk['trestbps']\n",
    "    print(\"\\nOriginal DataFrame:\")\n",
    "    print(df_risk)\n",
    "    \n",
    "    exp = exps_ideal[i]\n",
    "    if exp[0] is not None:\n",
    "        df_cf = exp[0].cf_examples_list[0].final_cfs_df\n",
    "        \n",
    "        for j in range(len(df_cf)):\n",
    "            cf_chol = df_cf['chol'].iloc[j]\n",
    "            cf_trestbps = df_cf['trestbps'].iloc[j] if 'trestbps' in df_cf.columns else None\n",
    "            \n",
    "            # Check if 'chol' and 'target' are not None\n",
    "            if pd.notna(cf_chol) and df_risk['target'].notna().all():\n",
    "                intervention_dict = {'chol': lambda chol: cf_chol}\n",
    "            elif pd.isna(cf_chol) and pd.notna(cf_trestbps) and df_risk['target'].notna().all():\n",
    "                intervention_dict = {'trestbps': lambda trestbps: cf_trestbps}\n",
    "            else:\n",
    "                print(\"chol or target is None\")\n",
    "                continue\n",
    "\n",
    "            cf_samples = gcm.interventional_samples(causal_model, intervention_dict, observed_data=df_risk)\n",
    "            cf_samples['exang'] = cf_samples['exang'].clip(0, 1).astype('category')\n",
    "            cf_samples_filtered = cf_samples[\n",
    "                (cf_samples['chol'] < chol_risk)\n",
    "                                   \n",
    "            ]\n",
    "            \n",
    "            # Check if any of the target values in filtered cf_samples are 0\n",
    "            if (cf_samples_filtered['target'] == 0).any():\n",
    "                # Filter the counterfactual samples that resulted in target = 0\n",
    "                cf_worked = cf_samples_filtered[cf_samples_filtered['target'] == 0]\n",
    "                for index, row in cf_worked.iterrows():\n",
    "                    print(\"\\nCounterfactual DataFrame:\")\n",
    "                    print(cf_samples_filtered)\n",
    "                    print(\"\\nCholesterol Level:\", row['chol'])\n",
    "                    print(\"Trestbps Level:\", row['trestbps'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''for i in range(len(df_high_risk_tp)):\n",
    "    df_risk = df_high_risk_tp.iloc[[i]]\n",
    "    # Apply the filtering conditions\n",
    "    age = df_risk['age']\n",
    "    chol_risk = df_risk['chol']\n",
    "    thalach_risk = df_risk['thalach']\n",
    "    print(\"\\nOriginal DataFrame:\")\n",
    "    print(df_risk)\n",
    "    \n",
    "    exp = exps_ideal[i]\n",
    "    if exp[0] is not None:\n",
    "        df_cf = exp[0].cf_examples_list[0].final_cfs_df\n",
    "        \n",
    "        for j in range(len(df_cf)):\n",
    "            cf_chol = df_cf['chol'].iloc[j]\n",
    "            cf_thalach = df_cf['thalach'].iloc[j]\n",
    "            \n",
    "            # Check if 'chol' and 'target' are not None\n",
    "            if pd.notna(cf_chol) and pd.notna(cf_thalach) and df_risk['target'].notna().all():\n",
    "                cf_samples = gcm.interventional_samples(causal_model, {'chol': lambda chol: cf_chol, 'thalach': lambda thalach: cf_thalach}, observed_data=df_risk)\n",
    "                cf_samples['exang'] = cf_samples['exang'].clip(0, 1).astype('category')\n",
    "                \n",
    "               \n",
    "                \n",
    "                cf_samples_filtered = cf_samples[\n",
    "                    (cf_samples['chol'] < chol_risk)                     \n",
    "                ]\n",
    "                \n",
    "                # Check if any of the target values in filtered cf_samples are 0\n",
    "                if (cf_samples_filtered['target'] == 0).any():\n",
    "                    # Filter the counterfactual samples that resulted in target = 0\n",
    "                    cf_worked = cf_samples_filtered[cf_samples_filtered['target'] == 0]\n",
    "                    for index, row in cf_worked.iterrows():\n",
    "                        print(\"\\nCounterfactual DataFrame:\")\n",
    "                        print(cf_samples_filtered)\n",
    "                        print(\"\\nCholesterol Level:\", row['chol'])\n",
    "                        print(\"Thalach Level:\", row['thalach'])\n",
    "            else:\n",
    "                print(\"chol or target is None\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_high_risk_tp)):\n",
    "    df_risk = df_high_risk_tp.iloc[[i]]\n",
    "    # Apply the filtering conditions\n",
    "    age = df_risk['age']\n",
    "    chol_risk = df_risk['chol']\n",
    "    thalach_risk = df_risk['thalach']\n",
    "    print(\"\\nOriginal DataFrame:\")\n",
    "    print(df_risk)\n",
    "    \n",
    "    exp = exps_feasible[i]\n",
    "    if exp[0] is not None:\n",
    "        df_cf = exp[0].cf_examples_list[0].final_cfs_df\n",
    "        \n",
    "        for j in range(len(df_cf)):\n",
    "            cf_chol = df_cf['chol'].iloc[j]\n",
    "            cf_thalach = df_cf['thalach'].iloc[j]\n",
    "            \n",
    "            # Check if 'chol' and 'target' are not None\n",
    "            if pd.notna(cf_chol) and pd.notna(cf_thalach) and df_risk['target'].notna().all():\n",
    "                cf_samples = gcm.interventional_samples(causal_model, {'chol': lambda chol: cf_chol, 'thalach': lambda thalach: cf_thalach}, observed_data=df_risk)\n",
    "                cf_samples['exang'] = cf_samples['exang'].clip(0, 1).astype('category')\n",
    "                \n",
    "               \n",
    "                \n",
    "                cf_samples_filtered = cf_samples[\n",
    "                    (cf_samples['chol'] < chol_risk) &\n",
    "                    (cf_samples['thalach'] > thalach_risk) &\n",
    "                    (cf_samples['thalach'] < (220 - age))\n",
    "                ]\n",
    "                \n",
    "                # Check if any of the target values in filtered cf_samples are 0\n",
    "                if (cf_samples_filtered['target'] == 0).any():\n",
    "                    # Filter the counterfactual samples that resulted in target = 0\n",
    "                    cf_worked = cf_samples_filtered[cf_samples_filtered['target'] == 0]\n",
    "                    for index, row in cf_worked.iterrows():\n",
    "                        print(\"\\nCounterfactual DataFrame:\")\n",
    "                        print(cf_samples_filtered)\n",
    "                        print(\"\\nCholesterol Level:\", row['chol'])\n",
    "                        print(\"Thalach Level:\", row['thalach'])\n",
    "            else:\n",
    "                print(\"chol or target is None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_high_risk_tp)):\n",
    "    df_risk = df_high_risk_tp.iloc[[i]]\n",
    "    # Apply the filtering conditions\n",
    "    age = df_risk['age']\n",
    "    chol_risk = df_risk['chol']\n",
    "    thalach_risk = df_risk['thalach']\n",
    "    print(\"\\nOriginal DataFrame:\")\n",
    "    print(df_risk)\n",
    "    \n",
    "    exp = exps_feasible_[i]\n",
    "    if exp[0] is not None:\n",
    "        df_cf = exp[0].cf_examples_list[0].final_cfs_df\n",
    "        \n",
    "        for j in range(len(df_cf)):\n",
    "            cf_chol = df_cf['chol'].iloc[j]\n",
    "            cf_thalach = df_cf['thalach'].iloc[j]\n",
    "            \n",
    "            # Check if 'chol' and 'target' are not None\n",
    "            if pd.notna(cf_chol) and pd.notna(cf_thalach) and df_risk['target'].notna().all():\n",
    "                cf_samples = gcm.interventional_samples(causal_model, {'chol': lambda chol: cf_chol, 'thalach': lambda thalach: cf_thalach}, observed_data=df_risk)\n",
    "                cf_samples['exang'] = cf_samples['exang'].clip(0, 1).astype('category')\n",
    "                \n",
    "               \n",
    "                \n",
    "                cf_samples_filtered = cf_samples[\n",
    "                    (cf_samples['chol'] < chol_risk) &\n",
    "                    (cf_samples['thalach'] > thalach_risk) &\n",
    "                    (cf_samples['thalach'] < (220 - age))\n",
    "                ]\n",
    "                \n",
    "                # Check if any of the target values in filtered cf_samples are 0\n",
    "                if (cf_samples_filtered['target'] == 0).any():\n",
    "                    # Filter the counterfactual samples that resulted in target = 0\n",
    "                    cf_worked = cf_samples_filtered[cf_samples_filtered['target'] == 0]\n",
    "                    for index, row in cf_worked.iterrows():\n",
    "                        print(\"\\nCounterfactual DataFrame:\")\n",
    "                        print(cf_samples_filtered)\n",
    "                        print(\"\\nCholesterol Level:\", row['chol'])\n",
    "                        print(\"Thalach Level:\", row['thalach'])\n",
    "            else:\n",
    "                print(\"chol or target is None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_high_risk_tp)):\n",
    "    df_risk = df_high_risk_tp.iloc[[i]]\n",
    "    print(\"\\nOriginal DataFrame:\")\n",
    "    print(df_risk)\n",
    "    \n",
    "    exp = exps_ideal[i]\n",
    "    if exp[0] is not None:\n",
    "        df_cf = exp[0].cf_examples_list[0].final_cfs_df\n",
    "        \n",
    "        for j in range(len(df_cf)):\n",
    "            cf_chol = df_cf['chol'].iloc[j]\n",
    "            cf_thalach = df_cf['thalach'].iloc[j]\n",
    "            \n",
    "            # Check if 'chol' and 'target' are not None\n",
    "            if pd.notna(cf_chol) and pd.notna(cf_thalach) and df_risk['target'].notna().all():\n",
    "                cf_samples = gcm.interventional_samples(causal_model, {'chol': lambda chol: cf_chol, 'thalach': lambda thalach: cf_thalach}, observed_data=df_risk)\n",
    "                cf_samples['exang'] = cf_samples['exang'].clip(0, 1).astype('category')\n",
    "                \n",
    "                # Check if any of the target values in cf_samples are 0\n",
    "                if (cf_samples['target'] == 0).any():\n",
    "                    # Filter the counterfactual samples that resulted in target = 0\n",
    "                    cf_worked = cf_samples[cf_samples['target'] == 0]\n",
    "                    for index, row in cf_worked.iterrows():\n",
    "                        print(\"\\nCounterfactual DataFrame:\")\n",
    "                        print(cf_samples)\n",
    "                        print(\"\\nCholesterol Level:\", row['chol'])\n",
    "                        print(\"Thalach Level:\", row['thalach'])\n",
    "            else:\n",
    "                print(\"chol or target is None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_high_risk_tp[3:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "samples_chol = gcm.interventional_samples(causal_model, {'chol': lambda chol:208,'thalach': lambda thalach:159}, observed_data=df_high_risk_tp[3:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_high_risk_tp[3:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_chol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples['exang'] = samples['exang'].clip(0, 1).astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure both DataFrames have the same index\n",
    "df_risk = df_risk.reset_index(drop=True)\n",
    "samples = samples.reset_index(drop=True)\n",
    "\n",
    "# Find rows where exang has changed from 1 to 0\n",
    "changed_rows = df_risk[(df_risk['exang'] == 1) & (samples['exang'] == 0)]\n",
    "\n",
    "# Display the rows\n",
    "print(changed_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(samples['target'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_chol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update 'sex' column\n",
    "df['sex'] = df['sex'].replace({1: 'Male', 0: 'Female'})\n",
    "# Update 'cp' column\n",
    "df['cp'] = df['cp'].replace({1: 'typical angina', 2: 'atypical angina', 3: 'non-anginal pain', 4: 'asymptomatic'})\n",
    "# Update 'fbs' column\n",
    "df['fbs'] = df['fbs'].replace({1: 'True', 0: 'False'})\n",
    "# Update 'restecg' column\n",
    "df['restecg'] = df['restecg'].replace({0: 'normal', 1: 'ST-T wave abnormality', 2: 'probable or definite left ventricular hypertrophy'})\n",
    "# Update 'exang' column\n",
    "df['exang'] = df['exang'].replace({1: 'yes', 0: 'no'})\n",
    "# Update 'slope' column\n",
    "df['slope'] = df['slope'].replace({1: 'upsloping', 2: 'flat', 3: 'downsloping'})\n",
    "# Update 'target' column\n",
    "df['target'] = df['target'].replace({1: 'yes', 0: 'no'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_risk = df[df['target'] == 'yes'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_data():\n",
    "    dict_strings = []\n",
    "    df = pd.read_csv(\"heart_statlog_cleveland_hungary_final.csv\")\n",
    "    # Update 'sex' column\n",
    "    df['sex'] = df['sex'].replace({1: 'Male', 0: 'Female'})\n",
    "    # Update 'cp' column\n",
    "    df['cp'] = df['cp'].replace({1: 'typical angina', 2: 'atypical angina', 3: 'non-anginal pain', 4: 'asymptomatic'})\n",
    "    # Update 'fbs' column\n",
    "    df['fbs'] = df['fbs'].replace({1: 'True', 0: 'False'})\n",
    "    # Update 'restecg' column\n",
    "    df['restecg'] = df['restecg'].replace({0: 'normal', 1: 'ST-T wave abnormality', 2: 'probable or definite left ventricular hypertrophy'})\n",
    "    # Update 'exang' column\n",
    "    df['exang'] = df['exang'].replace({1: 'yes', 0: 'no'})\n",
    "    # Update 'slope' column\n",
    "    df['slope'] = df['slope'].replace({1: 'upsloping', 2: 'flat', 3: 'downsloping'})\n",
    "    # Update 'target' column\n",
    "    df['target'] = df['target'].replace({1: 'yes', 0: 'no'})\n",
    "    df_risk = df[df['target'] == 'yes'].reset_index(drop=True)\n",
    "    for i in range(len(df_risk)):\n",
    "        patient_records = df_risk.iloc[i]\n",
    "        dict_string = json.dumps(patient_records.to_dict())\n",
    "        dict_strings.append(dict_string)\n",
    "    return dict_strings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset_Description = \"\"\"age: This is the patient’s age, measured in years.\n",
    "10\n",
    "2. sex: This variable indicates the patient’s gender, with 1 signifying\n",
    "Male and 0 signifying Female.\n",
    "3. cp: This attribute describes the kind of chest discomfort experienced\n",
    "by the patient, with 1 indicating typical angina, 2 indicating atypical\n",
    "angina, 3 indicating non-anginal pain, and four indicating asymptomatic.\n",
    "4. trestbps: Upon hospital admission, the patient’s resting blood pressure\n",
    "(in mmHg).\n",
    "5. chol: This variable measures the patient’s cholesterol level in mg/dl.\n",
    "6. fbs: This attribute indicates whether the patient’s fasting blood sugar\n",
    "level exceeds 120 mg/dl (1 = True; 0 = False).\n",
    "7. restecg: This variable represents the resting electrocardiographic measurement,\n",
    "with 0 indicating normal, 1 indicating ST-T wave abnormality,\n",
    "and 2 indicating probable or definite left ventricular hypertrophy\n",
    "by Estes’ criteria.\n",
    "8. thalach: This attribute denotes the maximum heart rate the individual\n",
    "achieves during exercise.\n",
    "9. exang: This variable indicates whether the patient experienced angina\n",
    "caused by exercise (1 = yes; 0 = no).\n",
    "10. oldpeak: This attribute refers to the ST depression induced by exercise\n",
    "relative to rest (‘ST’ refers to positions on the ECG plot).\n",
    "11. slope: This variable describes the slope of the peak exercise ST segment\n",
    "(1: upsloping, 2: flat, 3: downsloping).\n",
    "12. target: This attribute indicates whether the patient has heart disease/\n",
    "CVD (0 = no, 1 = yes).\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_records = read_data()\n",
    "patient_descriptions = create_patient_descriptions(patient_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(patient_descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_info = patient_descriptions[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_cvd_counterfactual_wo_constraints = []\n",
    "for idx,patient_record in enumerate(patient_descriptions):\n",
    "    print(idx)\n",
    "    patient_cvd_counterfactual_wo_constraints.append(create_patient_cf_wo_constraints(patient_record))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_cvd_counterfactual_wo_constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_cvd_counterfactual = []\n",
    "for idx,patient_record in enumerate(patient_descriptions):\n",
    "    print(idx)\n",
    "    patient_cvd_counterfactual.append(create_patient_cf(patient_record))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add 'patient_descriptions' and 'patient_cvd_counterfactual' to 'df_risk'\n",
    "df_risk['patient_descriptions'] = patient_descriptions\n",
    "df_risk['patient_cvd_counterfactual'] = patient_cvd_counterfactual\n",
    "\n",
    "# Save 'df_risk' as a CSV file\n",
    "df_risk.to_csv('df_risk_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the values for each preventive measure and put them into separate columns\n",
    "df_risk['Cholesterol'] = df_risk['patient_cvd_counterfactual'].str.extract(r'Cholesterol\\s*:\\s*(\\d+)')\n",
    "df_risk['Resting Blood Pressure'] = df_risk['patient_cvd_counterfactual'].str.extract(r'Resting Blood Pressure\\s*:\\s*(\\d+)')\n",
    "df_risk['Max Heart Rate'] = df_risk['patient_cvd_counterfactual'].str.extract(r'Max Heart Rate\\s*:\\s*(\\d+)')\n",
    "df_risk['Fasting Blood Sugar'] = df_risk['patient_cvd_counterfactual'].str.extract(r'Fasting Blood Sugar\\s*:\\s*(\\d+)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_risk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get descriptive statistics of the 'Cholesterol', 'Resting Blood Pressure', and 'Max Heart Rate' columns\n",
    "df_risk[['Cholesterol', 'Resting Blood Pressure', 'Max Heart Rate']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list into a DataFrame\n",
    "df = pd.DataFrame(patient_cvd_counterfactual, columns=['preventive_measures'])\n",
    "\n",
    "# Split the 'preventive_measures' column into separate columns\n",
    "df = df['preventive_measures'].str.split(',', expand=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necessary and Sufficient Causes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note: The openai-python library support for Azure OpenAI is in preview.\n",
    "      #Note: This code sample requires OpenAI Python library version 0.28.1 or lower.\n",
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_base = \"<OpenAI url>\"\n",
    "openai.api_version = \"2023-07-01-preview\"\n",
    "openai.api_key = \"<key>\"\n",
    "necessary_cause = \"Causes\"  # replace with actual necessary causes\n",
    "sufficient_cause = \"Causes\"  # replace with actual sufficient causes\n",
    "\n",
    "cause_dict = {\"Necessary Cause\": necessary_cause, \"Sufficient Cause\": sufficient_cause}\n",
    "\n",
    "message_text = [{\"role\":\"system\",\n",
    "\"content\":f\"\"\"You are an expert in Causal Reasoning (Actual Causality). Your aware of the INUS Causation.\n",
    "Here are the patient details:\n",
    "--- \n",
    "{patient_info}\n",
    "---\n",
    "Provide necessary and sufficient cause(s) for the patient's heart disease separately.\n",
    "Answer with medical explantions in precise manner in the following format:\n",
    "---\n",
    "{cause_dict}\n",
    "---\n",
    "\"\"\"}]\n",
    "\n",
    "completion = openai.ChatCompletion.create(\n",
    "  engine=\"gpt-4-32k-deployment\",\n",
    "  messages = message_text,\n",
    "  temperature=0.0,\n",
    "  max_tokens=800,\n",
    "  top_p=0.95,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0,\n",
    "  stop=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
