{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from langchain_experimental.agents import create_pandas_dataframe_agent\n",
    "import os\n",
    "import json\n",
    "import openai\n",
    "from openai import AzureOpenAI\n",
    "#from langchain.llms import AzureOpenAI\n",
    "#from langchain_openai import AzureChatOpenAI\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from causalnex.structure import StructureModel\n",
    "    \n",
    "sm_manual = StructureModel()\n",
    "sm_manual.add_edges_from(\n",
    "    [\n",
    "    ('age', 'chol'),\n",
    "    ('age', 'trestbps'),\n",
    "    ('sex', 'chol'),\n",
    "    ('sex', 'trestbps'),\n",
    "    ('sex', 'target'),\n",
    "    ('cp', 'target'),\n",
    "    ('trestbps', 'target'),\n",
    "    ('chol', 'target'),\n",
    "    ('fbs', 'target'),\n",
    "    ('restecg', 'target'),\n",
    "    ('thalach', 'target'),\n",
    "    ('thalach', 'exang'),\n",
    "    ('exang', 'target'),\n",
    "    ('oldpeak', 'target'),\n",
    "    ('oldpeak', 'exang'),\n",
    "    ('slope', 'target'),\n",
    "    ('slope', 'exang')\n",
    "    ],\n",
    "    origin=\"expert\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"heart_statlog_cleveland_hungary_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =  df.dropna()\n",
    "df = df[df['chol'] !=0]\n",
    "df = df[df['trestbps'] !=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'age'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m bn \u001b[38;5;241m=\u001b[39m BayesianNetwork(sm_manual)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Updating the model on the whole dataset\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[43mbn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_cpds\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBayesianEstimator\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbayes_prior\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mK2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pmkul\\Dropbox\\Counterfactual_Analysis\\LLM\\causalnexenv\\lib\\site-packages\\causalnex\\network\\network.py:417\u001b[0m, in \u001b[0;36mBayesianNetwork.fit_cpds\u001b[1;34m(self, data, method, bayes_prior, equivalent_sample_size)\u001b[0m\n\u001b[0;32m    414\u001b[0m state_names \u001b[38;5;241m=\u001b[39m {k: \u001b[38;5;28mlist\u001b[39m(v\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_node_states\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m    416\u001b[0m transformed_data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# type: pd.DataFrame\u001b[39;00m\n\u001b[1;32m--> 417\u001b[0m transformed_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_state_to_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransformed_data\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnodes\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMaximumLikelihoodEstimator\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    420\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[0;32m    421\u001b[0m         data\u001b[38;5;241m=\u001b[39mtransformed_data,\n\u001b[0;32m    422\u001b[0m         estimator\u001b[38;5;241m=\u001b[39mMaximumLikelihoodEstimator,\n\u001b[0;32m    423\u001b[0m         state_names\u001b[38;5;241m=\u001b[39mstate_names,\n\u001b[0;32m    424\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\pmkul\\Dropbox\\Counterfactual_Analysis\\LLM\\causalnexenv\\lib\\site-packages\\causalnex\\network\\network.py:379\u001b[0m, in \u001b[0;36mBayesianNetwork._state_to_index\u001b[1;34m(self, df, nodes)\u001b[0m\n\u001b[0;32m    376\u001b[0m cols \u001b[38;5;241m=\u001b[39m nodes \u001b[38;5;28;01mif\u001b[39;00m nodes \u001b[38;5;28;01melse\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m cols:\n\u001b[1;32m--> 379\u001b[0m     df[col] \u001b[38;5;241m=\u001b[39m df[col]\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_node_states\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[0;32m    381\u001b[0m df\u001b[38;5;241m.\u001b[39mis_copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "\u001b[1;31mKeyError\u001b[0m: 'age'"
     ]
    }
   ],
   "source": [
    "from causalnex.network import BayesianNetwork\n",
    "from causalnex.inference import InferenceEngine\n",
    "\n",
    "bn = BayesianNetwork(sm_manual)\n",
    "\n",
    "# Updating the model on the whole dataset\n",
    "bn.fit_cpds(df, method=\"BayesianEstimator\", bayes_prior=\"K2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgmpy.models import BayesianNetwork\n",
    "from pgmpy.inference import VariableElimination\n",
    "from pgmpy.factors.discrete import TabularCPD\n",
    "from pgmpy.inference import CausalInference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discretize continuous variables\n",
    "df['age'] = pd.cut(df['age'], bins=5, labels=False)\n",
    "df['chol'] = pd.cut(df['chol'], bins=5, labels=False)\n",
    "df['trestbps'] = pd.cut(df['trestbps'], bins=5, labels=False)\n",
    "df['thalach'] = pd.cut(df['thalach'], bins=5, labels=False)\n",
    "df['oldpeak'] = pd.cut(df['oldpeak'], bins=5, labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discretize continuous variables and store the bin edges\n",
    "age_bins = pd.cut(df['age'], bins=5, labels=False, retbins=True)\n",
    "chol_bins = pd.cut(df['chol'], bins=5, labels=False, retbins=True)\n",
    "trestbps_bins = pd.cut(df['trestbps'], bins=5, labels=False, retbins=True)\n",
    "thalach_bins = pd.cut(df['thalach'], bins=5, labels=False, retbins=True)\n",
    "oldpeak_bins = pd.cut(df['oldpeak'], bins=5, labels=False, retbins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['chol'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BayesianNetwork([(\"age\", \"chol\"),\n",
    "    (\"age\", \"trestbps\"),\n",
    "    (\"sex\", \"chol\"),\n",
    "    (\"sex\", \"trestbps\"),\n",
    "    (\"sex\", \"target\"),\n",
    "    (\"cp\", \"target\"),\n",
    "    (\"trestbps\", \"target\"),\n",
    "    (\"chol\", \"target\"),\n",
    "    (\"fbs\", \"target\"),\n",
    "    (\"restecg\", \"target\"),\n",
    "    (\"thalach\", \"target\"),\n",
    "    (\"thalach\", \"exang\"),\n",
    "    (\"exang\", \"target\"),\n",
    "    (\"oldpeak\", \"target\"),\n",
    "    (\"oldpeak\", \"exang\"),\n",
    "    (\"slope\", \"target\"),\n",
    "    (\"slope\", \"exang\")\n",
    " ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "print(df.head())\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "# Filter the DataFrame to find a row where target is 1\n",
    "target_1_row = df[df['target'] == 1].iloc[1]\n",
    "\n",
    "# Create an evidence dictionary from the selected row\n",
    "evidence = {\n",
    "    'age': target_1_row['age'],\n",
    "    'sex': target_1_row['sex'],\n",
    "    'chol': target_1_row['chol'],\n",
    "    'trestbps': target_1_row['trestbps'],\n",
    "    'cp': target_1_row['cp'],\n",
    "    'fbs': target_1_row['fbs'],\n",
    "    'restecg': target_1_row['restecg'],\n",
    "    'thalach': target_1_row['thalach'],\n",
    "    'exang': target_1_row['exang'],\n",
    "    'oldpeak': target_1_row['oldpeak'],\n",
    "    'slope': target_1_row['slope']\n",
    "}\n",
    "\n",
    "print(evidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sample = df.sample(n=100, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgmpy.estimators import MaximumLikelihoodEstimator\n",
    "from pgmpy.inference import BeliefPropagation\n",
    "\n",
    "\n",
    "# Fit the model to the data\n",
    "model.fit(data_sample, estimator=MaximumLikelihoodEstimator)\n",
    "\n",
    "# Initialize the BeliefPropagation object\n",
    "belief_propagation = BeliefPropagation(model)\n",
    "\n",
    "# Set the evidence for the observed variables\n",
    "#evidence = {'age': 45, 'sex': 1, 'chol': 200}\n",
    "\n",
    "# Perform approximate inference\n",
    "# Example: What would be the effect on 'target' if 'chol' was set to 150?\n",
    "belief_propagation.do_intervention({'chol': 190})\n",
    "approximate_result = belief_propagation.query(variables=['target'], evidence=evidence)\n",
    "\n",
    "# Print the approximate result\n",
    "print(approximate_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "nx.draw(model)\n",
    "plt.show()'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bnlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'bnlearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbnlearn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mbn\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'bnlearn'"
     ]
    }
   ],
   "source": [
    "import bnlearn as bn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define the structure of the Bayesian Network\n",
    "edges = [\n",
    "    (\"age\", \"chol\"),\n",
    "    (\"age\", \"trestbps\"),\n",
    "    (\"sex\", \"chol\"),\n",
    "    (\"sex\", \"trestbps\"),\n",
    "    (\"sex\", \"target\"),\n",
    "    (\"cp\", \"target\"),\n",
    "    (\"trestbps\", \"target\"),\n",
    "    (\"chol\", \"target\"),\n",
    "    (\"fbs\", \"target\"),\n",
    "    (\"restecg\", \"target\"),\n",
    "    (\"thalach\", \"target\"),\n",
    "    (\"thalach\", \"exang\"),\n",
    "    (\"exang\", \"target\"),\n",
    "    (\"oldpeak\", \"target\"),\n",
    "    (\"oldpeak\", \"exang\"),\n",
    "    (\"slope\", \"target\"),\n",
    "    (\"slope\", \"exang\")\n",
    "]\n",
    "\n",
    "# Create the Bayesian Network model\n",
    "model = bn.make_DAG(edges)\n",
    "\n",
    "# Fit the model to the data\n",
    "model = bn.parameter_learning.fit(model, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyAgrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyAgrum as gum\n",
    "import pyAgrum.lib.notebook as gnb\n",
    "import pyAgrum.causal as csl\n",
    "import pyAgrum.causal.notebook as cslnb\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pgmpy.models import BayesianNetwork\n",
    "from pgmpy.estimators import MaximumLikelihoodEstimator\n",
    "\n",
    "# Load the dataset\n",
    "#data = pd.read_csv('path_to_your_dataset.csv')\n",
    "\n",
    "# Preprocess the dataset (if necessary)\n",
    "# For example, handle missing values or discretize continuous variables\n",
    "# data = data.fillna(method='ffill')  # Example: forward fill missing values\n",
    "\n",
    "# Define the structure of the Bayesian Network\n",
    "model = BayesianNetwork([(\"age\", \"chol\"),\n",
    "                         (\"age\", \"trestbps\"),\n",
    "                         (\"sex\", \"chol\"),\n",
    "                         (\"sex\", \"trestbps\"),\n",
    "                         (\"sex\", \"target\"),\n",
    "                         (\"cp\", \"target\"),\n",
    "                         (\"trestbps\", \"target\"),\n",
    "                         (\"chol\", \"target\"),\n",
    "                         (\"fbs\", \"target\"),\n",
    "                         (\"restecg\", \"target\"),\n",
    "                         (\"thalach\", \"target\"),\n",
    "                         (\"thalach\", \"exang\"),\n",
    "                         (\"exang\", \"target\"),\n",
    "                         (\"oldpeak\", \"target\"),\n",
    "                         (\"oldpeak\", \"exang\"),\n",
    "                         (\"slope\", \"target\"),\n",
    "                         (\"slope\", \"exang\")])\n",
    "\n",
    "# Fit the model to the data\n",
    "model.fit(data, estimator=MaximumLikelihoodEstimator)\n",
    "\n",
    "# Print the learned CPDs\n",
    "for cpd in model.get_cpds():\n",
    "    print(cpd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update 'sex' column\n",
    "df['sex'] = df['sex'].replace({1: 'Male', 0: 'Female'})\n",
    "# Update 'cp' column\n",
    "df['cp'] = df['cp'].replace({1: 'typical angina', 2: 'atypical angina', 3: 'non-anginal pain', 4: 'asymptomatic'})\n",
    "# Update 'fbs' column\n",
    "df['fbs'] = df['fbs'].replace({1: 'True', 0: 'False'})\n",
    "# Update 'restecg' column\n",
    "df['restecg'] = df['restecg'].replace({0: 'normal', 1: 'ST-T wave abnormality', 2: 'probable or definite left ventricular hypertrophy'})\n",
    "# Update 'exang' column\n",
    "df['exang'] = df['exang'].replace({1: 'yes', 0: 'no'})\n",
    "# Update 'slope' column\n",
    "df['slope'] = df['slope'].replace({1: 'upsloping', 2: 'flat', 3: 'downsloping'})\n",
    "# Update 'target' column\n",
    "df['target'] = df['target'].replace({1: 'yes', 0: 'no'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_risk = df[df['target'] == 'yes'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_data():\n",
    "    dict_strings = []\n",
    "    df = pd.read_csv(\"heart_statlog_cleveland_hungary_final.csv\")\n",
    "    # Update 'sex' column\n",
    "    df['sex'] = df['sex'].replace({1: 'Male', 0: 'Female'})\n",
    "    # Update 'cp' column\n",
    "    df['cp'] = df['cp'].replace({1: 'typical angina', 2: 'atypical angina', 3: 'non-anginal pain', 4: 'asymptomatic'})\n",
    "    # Update 'fbs' column\n",
    "    df['fbs'] = df['fbs'].replace({1: 'True', 0: 'False'})\n",
    "    # Update 'restecg' column\n",
    "    df['restecg'] = df['restecg'].replace({0: 'normal', 1: 'ST-T wave abnormality', 2: 'probable or definite left ventricular hypertrophy'})\n",
    "    # Update 'exang' column\n",
    "    df['exang'] = df['exang'].replace({1: 'yes', 0: 'no'})\n",
    "    # Update 'slope' column\n",
    "    df['slope'] = df['slope'].replace({1: 'upsloping', 2: 'flat', 3: 'downsloping'})\n",
    "    # Update 'target' column\n",
    "    df['target'] = df['target'].replace({1: 'yes', 0: 'no'})\n",
    "    df_risk = df[df['target'] == 'yes'].reset_index(drop=True)\n",
    "    for i in range(len(df_risk)):\n",
    "        patient_records = df_risk.iloc[i]\n",
    "        dict_string = json.dumps(patient_records.to_dict())\n",
    "        dict_strings.append(dict_string)\n",
    "    return dict_strings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset_Description = \"\"\"age: This is the patient’s age, measured in years.\n",
    "10\n",
    "2. sex: This variable indicates the patient’s gender, with 1 signifying\n",
    "Male and 0 signifying Female.\n",
    "3. cp: This attribute describes the kind of chest discomfort experienced\n",
    "by the patient, with 1 indicating typical angina, 2 indicating atypical\n",
    "angina, 3 indicating non-anginal pain, and four indicating asymptomatic.\n",
    "4. trestbps: Upon hospital admission, the patient’s resting blood pressure\n",
    "(in mmHg).\n",
    "5. chol: This variable measures the patient’s cholesterol level in mg/dl.\n",
    "6. fbs: This attribute indicates whether the patient’s fasting blood sugar\n",
    "level exceeds 120 mg/dl (1 = True; 0 = False).\n",
    "7. restecg: This variable represents the resting electrocardiographic measurement,\n",
    "with 0 indicating normal, 1 indicating ST-T wave abnormality,\n",
    "and 2 indicating probable or definite left ventricular hypertrophy\n",
    "by Estes’ criteria.\n",
    "8. thalach: This attribute denotes the maximum heart rate the individual\n",
    "achieves during exercise.\n",
    "9. exang: This variable indicates whether the patient experienced angina\n",
    "caused by exercise (1 = yes; 0 = no).\n",
    "10. oldpeak: This attribute refers to the ST depression induced by exercise\n",
    "relative to rest (‘ST’ refers to positions on the ECG plot).\n",
    "11. slope: This variable describes the slope of the peak exercise ST segment\n",
    "(1: upsloping, 2: flat, 3: downsloping).\n",
    "12. target: This attribute indicates whether the patient has heart disease/\n",
    "CVD (0 = no, 1 = yes).\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "import os\n",
    "import concurrent.futures\n",
    "import time\n",
    "\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_base = \"https://dap-open-ai-swc.openai.azure.com/\"\n",
    "openai.api_version = \"2023-09-15-preview\"\n",
    "openai.api_key = \"1fc75eeca3934ae29b46d59cfda85968\"\n",
    "\n",
    "client = AzureOpenAI( azure_endpoint = \"https://dap-open-ai-swc.openai.azure.com/\", \n",
    "                    api_key= \"1fc75eeca3934ae29b46d59cfda85968\",  \n",
    "                    api_version=\"2023-05-15\"\n",
    "                    )\n",
    "\n",
    "    \n",
    "def create_patient_description (patient_record):\n",
    "    # Convert the patient record to a dictionary string\n",
    "    \n",
    "    #print(i)\n",
    "    dict_string = json.dumps(patient_record)\n",
    "\n",
    "    # Create the message text\n",
    "    message_text = [{\n",
    "        \"role\": \"system\",\n",
    "        \"content\": f\"\"\"You are a helpful assistant. Here is the dataset description {Dataset_Description}.\n",
    "        Describe this patient info\n",
    "        ---\n",
    "        {dict_string} \n",
    "        ---\n",
    "        in plain english for me. Be precise and concise.\n",
    "        \"\"\"}]\n",
    "\n",
    "    # Create the chat completion\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4-32k-deployment\",\n",
    "        messages=message_text,\n",
    "        temperature=0.0,\n",
    "        max_tokens=800,\n",
    "        top_p=0.95,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        stop=None\n",
    "    )\n",
    "\n",
    "    # Return the generated description\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_patient_description_with_retry(patient_record):\n",
    "    retries = 0\n",
    "    while True:\n",
    "        try:\n",
    "            return create_patient_description(patient_record)\n",
    "        except Exception as e:\n",
    "            if '429' in str(e):\n",
    "                print(f\"Rate limit exceeded. Retrying after {2**retries} seconds.\")\n",
    "                time.sleep(2**retries)\n",
    "                retries += 1\n",
    "            else:\n",
    "                print(f\"An error occurred: {e}\")\n",
    "                return None\n",
    "\n",
    "def create_patient_descriptions(patient_records):\n",
    "    # Create a thread pool executor\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        patient_descriptions = list(executor.map(create_patient_description_with_retry, patient_records))\n",
    "\n",
    "    return patient_descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_records = read_data()\n",
    "patient_descriptions = create_patient_descriptions(patient_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(patient_descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_info = patient_descriptions[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def create_patient_cf (patient_record):\n",
    "    # Convert the patient record to a dictionary string \n",
    "    client = AzureOpenAI( azure_endpoint = \"https://dap-open-ai-swc.openai.azure.com/\", \n",
    "                        api_key= \"1fc75eeca3934ae29b46d59cfda85968\",  \n",
    "                        api_version=\"2023-05-15\"\n",
    "                        )\n",
    "\n",
    "    message_text = [{\"role\":\"system\",\n",
    "        \"content\":f\"\"\"You are a helpful assistant in Counterfactual Reasoning.\n",
    "        Here are the patient details:\n",
    "        --- \n",
    "        {patient_record}\n",
    "        ---\n",
    "        What should the patient do specifically to prevent heart disease?\n",
    "        Answer in precise comma separated manner in the following format:\n",
    "        ---\n",
    "        {{\"Preventive Measures\": [\"(measure1:value1), (measure2:value2),...\"]}}\n",
    "        ---\n",
    "        Restrict the preventive measures based on the patient's health data provided to you. Restrict actionable insights to Cholestrol, Resting Blood Pressure, Max Heart Rate and fasting blood sugar levels.\n",
    "        Here are the constraints. The counterfactual cholestrol should be lesser than patient's Cholestrol cannot be greater than 200.\n",
    "        Counterfactual Resting Blood Pressure and should be lesser than patient's Resting Blood Pressure and cannot be greater than 120. \n",
    "        Counterfactual Max heat rate should be greater than patient's current max heart rate should be lower than 220-Age.\n",
    "        Give a specific number for each preventive measure. Do not hallucinate. Don't provide general advice and say don't know if you can't provide a specific number.\n",
    "        \"\"\"}]\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "            model=\"gpt-4-32k-deployment\",\n",
    "            messages=message_text,\n",
    "            temperature=0.0,\n",
    "            max_tokens=800,\n",
    "            top_p=0.95,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0,\n",
    "            stop=None\n",
    "        )\n",
    "    \n",
    "    return completion.choices[0].message.content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def create_patient_cf_wo_constraints (patient_record):\n",
    "    # Convert the patient record to a dictionary string \n",
    "    client = AzureOpenAI( azure_endpoint = \"https://dap-open-ai-swc.openai.azure.com/\", \n",
    "                        api_key= \"1fc75eeca3934ae29b46d59cfda85968\",  \n",
    "                        api_version=\"2023-05-15\"\n",
    "                        )\n",
    "\n",
    "    message_text = [{\"role\":\"system\",\n",
    "        \"content\":f\"\"\"You are a helpful assistant in Counterfactual Reasoning.\n",
    "        Here are the patient details:\n",
    "        --- \n",
    "        {patient_record}\n",
    "        ---\n",
    "        What should the patient do specifically to prevent heart disease?\n",
    "        Answer in precise comma separated manner in the following format:\n",
    "        ---\n",
    "        {{\"Preventive Measures\": [\"(measure1:value1), (measure2:value2),...\"]}}\n",
    "        ---\n",
    "        Restrict the preventive measures based on the patient's health data provided to you. Restrict actionable insights to Cholestrol, Resting Blood Pressure, Max Heart Rate and fasting blood sugar levels.\n",
    "        Give a specific number for each preventive measure. Do not hallucinate. Don't provide general advice and say don't know if you can't provide a specific number.\n",
    "        \"\"\"}]\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "            model=\"gpt-4-32k-deployment\",\n",
    "            messages=message_text,\n",
    "            temperature=0.0,\n",
    "            max_tokens=800,\n",
    "            top_p=0.95,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0,\n",
    "            stop=None\n",
    "        )\n",
    "    \n",
    "    return completion.choices[0].message.content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_cvd_counterfactual_wo_constraints = []\n",
    "for idx,patient_record in enumerate(patient_descriptions):\n",
    "    print(idx)\n",
    "    patient_cvd_counterfactual_wo_constraints.append(create_patient_cf_wo_constraints(patient_record))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_cvd_counterfactual_wo_constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_cvd_counterfactual = []\n",
    "for idx,patient_record in enumerate(patient_descriptions):\n",
    "    print(idx)\n",
    "    patient_cvd_counterfactual.append(create_patient_cf(patient_record))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add 'patient_descriptions' and 'patient_cvd_counterfactual' to 'df_risk'\n",
    "df_risk['patient_descriptions'] = patient_descriptions\n",
    "df_risk['patient_cvd_counterfactual'] = patient_cvd_counterfactual\n",
    "\n",
    "# Save 'df_risk' as a CSV file\n",
    "df_risk.to_csv('df_risk_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the values for each preventive measure and put them into separate columns\n",
    "df_risk['Cholesterol'] = df_risk['patient_cvd_counterfactual'].str.extract(r'Cholesterol\\s*:\\s*(\\d+)')\n",
    "df_risk['Resting Blood Pressure'] = df_risk['patient_cvd_counterfactual'].str.extract(r'Resting Blood Pressure\\s*:\\s*(\\d+)')\n",
    "df_risk['Max Heart Rate'] = df_risk['patient_cvd_counterfactual'].str.extract(r'Max Heart Rate\\s*:\\s*(\\d+)')\n",
    "df_risk['Fasting Blood Sugar'] = df_risk['patient_cvd_counterfactual'].str.extract(r'Fasting Blood Sugar\\s*:\\s*(\\d+)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_risk.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get descriptive statistics of the 'Cholesterol', 'Resting Blood Pressure', and 'Max Heart Rate' columns\n",
    "df_risk[['Cholesterol', 'Resting Blood Pressure', 'Max Heart Rate']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list into a DataFrame\n",
    "df = pd.DataFrame(patient_cvd_counterfactual, columns=['preventive_measures'])\n",
    "\n",
    "# Split the 'preventive_measures' column into separate columns\n",
    "df = df['preventive_measures'].str.split(',', expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necessary and Sufficient Causes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note: The openai-python library support for Azure OpenAI is in preview.\n",
    "      #Note: This code sample requires OpenAI Python library version 0.28.1 or lower.\n",
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_base = \"https://dap-open-ai-swc.openai.azure.com/\"\n",
    "openai.api_version = \"2023-07-01-preview\"\n",
    "openai.api_key = \"1fc75eeca3934ae29b46d59cfda85968\"\n",
    "necessary_cause = \"Causes\"  # replace with actual necessary causes\n",
    "sufficient_cause = \"Causes\"  # replace with actual sufficient causes\n",
    "\n",
    "cause_dict = {\"Necessary Cause\": necessary_cause, \"Sufficient Cause\": sufficient_cause}\n",
    "\n",
    "message_text = [{\"role\":\"system\",\n",
    "\"content\":f\"\"\"You are an expert in Causal Reasoning (Actual Causality). Your aware of the INUS Causation.\n",
    "Here are the patient details:\n",
    "--- \n",
    "{patient_info}\n",
    "---\n",
    "Provide necessary and sufficient cause(s) for the patient's heart disease separately.\n",
    "Answer with medical explantions in precise manner in the following format:\n",
    "---\n",
    "{cause_dict}\n",
    "---\n",
    "\"\"\"}]\n",
    "\n",
    "completion = openai.ChatCompletion.create(\n",
    "  engine=\"gpt-4-32k-deployment\",\n",
    "  messages = message_text,\n",
    "  temperature=0.0,\n",
    "  max_tokens=800,\n",
    "  top_p=0.95,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0,\n",
    "  stop=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Responsibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note: The openai-python library support for Azure OpenAI is in preview.\n",
    "      #Note: This code sample requires OpenAI Python library version 0.28.1 or lower.\n",
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_base = \"https://dap-open-ai-swc.openai.azure.com/\"\n",
    "openai.api_version = \"2023-07-01-preview\"\n",
    "openai.api_key = \"1fc75eeca3934ae29b46d59cfda85968\"\n",
    "\n",
    "message_text = [{\"role\":\"system\",\"content\":f\"\"\"\n",
    "In the context of this dialog, define “responsibility” as the relative degree to which an event causally\n",
    "contributes to a particular outcome event, relative to\n",
    "other events that caused that outcome. Given two\n",
    "causal events that cause the same outcome event, one\n",
    "causal event can be more, less, or equally responsible\n",
    "relative to the other. In medical cases, the responsibility should be action-based.\n",
    "\n",
    "Based on this definition of responsibility and the patient info:{patient_info}, answer precisely which factor is/are most responsible for his/her of heart disease.\"\"\"}]\n",
    "\n",
    "completion = openai.ChatCompletion.create(\n",
    "  engine=\"gpt-4-32k-deployment\",\n",
    "  messages = message_text,\n",
    "  temperature=0.0,\n",
    "  max_tokens=800,\n",
    "  top_p=0.95,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0,\n",
    "  stop=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
