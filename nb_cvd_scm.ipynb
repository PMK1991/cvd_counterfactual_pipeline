{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import dice_ml\n",
    "from dice_ml.utils import helpers # helper functions\n",
    "from dice_ml import Data,Model,Dice\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "import time\n",
    "import threading\n",
    "from joblib import Parallel, delayed\n",
    "#from langchain_experimental.agents import create_pandas_dataframe_agent\n",
    "import os\n",
    "import json\n",
    "import openai\n",
    "from openai import AzureOpenAI\n",
    "#from langchain.llms import AzureOpenAI\n",
    "#from langchain_openai import AzureChatOpenAI\n",
    "import pandas as pd \n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "xgb.set_config(verbosity=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_heart_disease = pd.read_csv(\"heart_statlog_cleveland_hungary_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_heart_disease =  dataframe_heart_disease.dropna()\n",
    "dataframe_heart_disease =  dataframe_heart_disease.drop_duplicates()\n",
    "dataframe_heart_disease = dataframe_heart_disease[dataframe_heart_disease['chol'] !=0]\n",
    "dataframe_heart_disease = dataframe_heart_disease[dataframe_heart_disease['trestbps'] !=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into features and target label\n",
    "y = dataframe_heart_disease.target\n",
    "X = dataframe_heart_disease.drop(['target'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "\n",
    "categorical = X_train.columns.difference(numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create the preprocessing pipelines for both numeric and categorical data.\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "transformations = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numerical),\n",
    "        ('cat', categorical_transformer, categorical)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append classifier to preprocessing pipeline.\n",
    "# Now we have a full prediction pipeline.\n",
    "clf = Pipeline(steps=[('preprocessor', transformations),\n",
    "                      ('classifier', XGBClassifier())])\n",
    "xgb_model = clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the pipeline with the XGBClassifier\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', transformations),\n",
    "    ('classifier', XGBClassifier(max_depth=5, learning_rate=0.5, n_estimators=200, gamma=0))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model on the entire training set\n",
    "xgb_pipeline = pipeline.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = xgb_pipeline.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_high_risk_tp = X_test[(y_pred == 1) & (y_test == 1)].reset_index().drop(['index'], axis=1)\n",
    "#X_high_risk_tp = X_test[(y_pred == 1) & (y_test == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.concat([X_train, y_train], axis=1)\n",
    "\n",
    "\n",
    "# Create a DICE data object\n",
    "d = Data(dataframe=pd.DataFrame(train_data, columns=dataframe_heart_disease.columns), continuous_features=['age', 'trestbps', 'chol', 'thalach', 'oldpeak'],outcome_name='target')\n",
    "\n",
    "# Create a DICE model object\n",
    "m = Model(model=xgb_pipeline, backend=\"sklearn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideal Constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import queue\n",
    "\n",
    "df_no_counterfactuals = pd.DataFrame(columns=X_high_risk_tp.columns)\n",
    "def generate_cf(test_instance, timeout=10):\n",
    "    q = queue.Queue()\n",
    "\n",
    "    def target():\n",
    "        try:\n",
    "            result = Dice(d, m, method='genetic').generate_counterfactuals(test_instance, total_CFs=20, desired_class=\"opposite\",\n",
    "                                                                           features_to_vary=[\"trestbps\", \"chol\", \"fbs\"],\n",
    "                                                                           diversity_weight=5, proximity_weight=2, sparsity_weight=5,\n",
    "                                                                           permitted_range={ \"chol\": [100, 200], \"trestbps\": [100, 120] }\n",
    "                                                                           )\n",
    "            q.put(result)\n",
    "        except Exception as e:\n",
    "            print(\"No counterfactuals found for test instance:\", test_instance)\n",
    "            df_no_counterfactuals.append(test_instance)\n",
    "            q.put(None)\n",
    "\n",
    "    # Start a new thread to run the target function\n",
    "    thread = threading.Thread(target=target)\n",
    "    thread.start()\n",
    "\n",
    "    # Wait for the thread to finish or raise a timeout exception\n",
    "    thread.join(timeout)\n",
    "\n",
    "    if thread.is_alive():\n",
    "        # The thread is still running, so raise a timeout exception\n",
    "        print(\"No counterfactuals found for test instance-timed out:\", test_instance)\n",
    "        df_no_counterfactuals.append(test_instance)\n",
    "        q.put(None)\n",
    "    else:\n",
    "        # The thread has finished, so return the result\n",
    "        return q.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "\n",
    "exps_ideal = []\n",
    "num_cores = -1\n",
    "\n",
    "# Iterate over each instance of X_high_risk and generate counterfactuals\n",
    "for i in range(len(X_high_risk_tp)):\n",
    "    test_instance = X_high_risk_tp.iloc[[i]]\n",
    "    print(i)\n",
    "    exp = Parallel(n_jobs=num_cores)(delayed(generate_cf)(test_instance) for i in range(1))\n",
    "    exps_ideal.append(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "validity_list = []\n",
    "for exps in exps_ideal:\n",
    "    \n",
    "    if exps[0] is not None:\n",
    "       exp_df = exps[0].cf_examples_list[0].final_cfs_df\n",
    "       validity_list.append(xgb_pipeline.predict(exp_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened Array: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Sum of 1s: 302\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Flatten the nested array\n",
    "flattened_array = [item for sublist in validity_list for item in sublist]\n",
    "\n",
    "# Calculate the sum of 1s\n",
    "sum_of_ones = sum(item == 1 for item in flattened_array)\n",
    "\n",
    "print(\"Flattened Array:\", flattened_array)\n",
    "print(\"Sum of 1s:\", sum_of_ones)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feasible Constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import queue\n",
    "\n",
    "df_no_counterfactuals = pd.DataFrame(columns=X_high_risk_tp.columns)\n",
    "def generate_cf_feasible(test_instance, timeout=30):\n",
    "    q = queue.Queue()\n",
    "\n",
    "    def target():\n",
    "        try:\n",
    "            result = Dice(d, m, method='genetic').generate_counterfactuals(test_instance, total_CFs=20, desired_class=\"opposite\",\n",
    "                                                                           features_to_vary=[\"trestbps\", \"chol\", \"fbs\"],\n",
    "                                                                           #diversity_weight=5, proximity_weight=2, sparsity_weight=5,\n",
    "                                                                           permitted_range={\"trestbps\": [80, test_instance['trestbps'].values[0]-10],\n",
    "                                                                                            \"chol\": [100, test_instance['chol'].values[0]-0.1*test_instance['chol'].values[0]],\n",
    "                                                                                           }\n",
    "                                                                           )\n",
    "            q.put(result)\n",
    "        except Exception as e:\n",
    "            print(\"No counterfactuals found for test instance:\", test_instance)\n",
    "            df_no_counterfactuals.append(test_instance)\n",
    "            q.put(None)\n",
    "\n",
    "    # Start a new thread to run the target function\n",
    "    thread = threading.Thread(target=target)\n",
    "    thread.start()\n",
    "\n",
    "    # Wait for the thread to finish or raise a timeout exception\n",
    "    thread.join(timeout)\n",
    "\n",
    "    if thread.is_alive():\n",
    "        # The thread is still running, so raise a timeout exception\n",
    "        print(\"No counterfactuals found for test instance-timed out:\", test_instance)\n",
    "        df_no_counterfactuals.append(test_instance)\n",
    "        q.put(None)\n",
    "    else:\n",
    "        # The thread has finished, so return the result\n",
    "        return q.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "exps_feasible = []\n",
    "num_cores = -1\n",
    "\n",
    "# Iterate over each instance of X_high_risk and generate counterfactuals\n",
    "for i in range(len(X_high_risk_tp)):\n",
    "    test_instance = X_high_risk_tp.iloc[[i]]\n",
    "    print(i)\n",
    "    exp = Parallel(n_jobs=num_cores)(delayed(generate_cf_feasible)(test_instance) for i in range(1))\n",
    "    exps_feasible.append(exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "General Counterfactuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import queue\n",
    "\n",
    "df_no_counterfactuals = pd.DataFrame(columns=X_high_risk_tp.columns)\n",
    "def generate_cf_feasible_(test_instance, timeout=30):\n",
    "    q = queue.Queue()\n",
    "\n",
    "    def target():\n",
    "        try:\n",
    "            result = Dice(d, m, method='genetic').generate_counterfactuals(test_instance, total_CFs=20, desired_class=\"opposite\",\n",
    "                                                                           features_to_vary=[\"trestbps\", \"chol\", \"thalach\"],\n",
    "                                                                           #diversity_weight=5, proximity_weight=2, sparsity_weight=5,\n",
    "                                                                           #permitted_range={\"trestbps\": [80, test_instance['trestbps'].values[0]-1],\n",
    "                                                                           #                 \"chol\": [100, test_instance['chol'].values[0]-1],\n",
    "                                                                           #                 \"thalach\": [test_instance['thalach'].values[0]+1, 220 - test_instance['age'].values[0]]}\n",
    "                                                                           )\n",
    "            q.put(result)\n",
    "        except Exception as e:\n",
    "            print(\"No counterfactuals found for test instance:\", test_instance)\n",
    "            df_no_counterfactuals.append(test_instance)\n",
    "            q.put(None)\n",
    "\n",
    "    # Start a new thread to run the target function\n",
    "    thread = threading.Thread(target=target)\n",
    "    thread.start()\n",
    "\n",
    "    # Wait for the thread to finish or raise a timeout exception\n",
    "    thread.join(timeout)\n",
    "\n",
    "    if thread.is_alive():\n",
    "        # The thread is still running, so raise a timeout exception\n",
    "        print(\"No counterfactuals found for test instance-timed out:\", test_instance)\n",
    "        df_no_counterfactuals.append(test_instance)\n",
    "        q.put(None)\n",
    "    else:\n",
    "        # The thread has finished, so return the result\n",
    "        return q.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "exps_feasible_ = []\n",
    "num_cores = -1\n",
    "\n",
    "# Iterate over each instance of X_high_risk and generate counterfactuals\n",
    "for i in range(len(X_high_risk_tp)):\n",
    "    test_instance = X_high_risk_tp.iloc[[i]]\n",
    "    print(i)\n",
    "    exp = Parallel(n_jobs=num_cores)(delayed(generate_cf_feasible_)(test_instance) for i in range(1))\n",
    "    exps_feasible_.append(exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Structural Causal Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from networkx.drawing.nx_agraph import graphviz_layout\n",
    "\n",
    "# Define the edges\n",
    "edges = [\n",
    "    # Risk Factors -> Diseases\n",
    "    ('age', 'target'),\n",
    "    ('sex', 'target'),\n",
    "    ('chol', 'target'),\n",
    "    ('fbs', 'target'),\n",
    "    ('trestbps', 'target'),\n",
    "\n",
    "    # Diseases -> Symptoms\n",
    "    ('target', 'cp'),\n",
    "    ('target', 'restecg'),\n",
    "    ('target', 'thalach'),\n",
    "    ('target', 'exang'),\n",
    "    ('target', 'slope'),\n",
    "    ('target', 'oldpeak'),\n",
    "\n",
    "    # Direct Risk Factors -> Symptoms relationships\n",
    "    ('age', 'chol'),\n",
    "    ('age', 'trestbps'),\n",
    "    ('sex', 'trestbps'),\n",
    "    ('sex', 'chol'),\n",
    "    ('chol', 'trestbps'),\n",
    "    ('thalach', 'exang'),\n",
    "    ('exang', 'cp')\n",
    "]\n",
    "\n",
    "# Create a directed graph\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Add edges to the graph\n",
    "G.add_edges_from(edges)\n",
    "\n",
    "# Use graphviz_layout for a hierarchical arrangement of nodes\n",
    "plt.figure(figsize=(14, 10))\n",
    "pos = graphviz_layout(G, prog='dot')\n",
    "\n",
    "# Draw the graph with hierarchical layout\n",
    "nx.draw(\n",
    "    G, pos, with_labels=True, node_size=3000, node_color='lightcoral',\n",
    "    font_size=10, font_weight='bold', arrowsize=20\n",
    ")\n",
    "\n",
    "# Display the graph\n",
    "plt.title('Causal DAG for Cardiovascular Disease (CVD)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the structure of the DAG\n",
    "edges = [\n",
    "    ('age', 'chol'),\n",
    "    ('age', 'trestbps'),\n",
    "    ('sex', 'chol'),\n",
    "    ('sex', 'trestbps'),\n",
    "    ('sex', 'target'),\n",
    "    ('cp', 'target'),\n",
    "    ('trestbps', 'target'),\n",
    "    ('chol', 'target'),\n",
    "    ('chol', 'trestbps'),\n",
    "    ('fbs', 'target'),\n",
    "    ('restecg', 'target'),\n",
    "    ('thalach', 'target'),\n",
    "    ('thalach', 'exang'),\n",
    "    ('exang', 'target'),\n",
    "    ('oldpeak', 'target'),\n",
    "    ('oldpeak', 'exang'),\n",
    "    ('slope', 'target'),\n",
    "    ('slope', 'exang')\n",
    "]\n",
    "\n",
    "# Create a directed graph using NetworkX\n",
    "G = nx.DiGraph()\n",
    "G.add_edges_from(edges)\n",
    "\n",
    "# Plot the DAG\n",
    "plt.figure(figsize=(12, 8))\n",
    "pos = nx.spring_layout(G)\n",
    "nx.draw(G, pos, with_labels=True, node_size=3000, node_color='lightblue', font_size=10, font_weight='bold', arrowsize=20)\n",
    "plt.title('DAG for Causal Discovery in Cardiology')\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"heart_statlog_cleveland_hungary_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =  df.dropna()\n",
    "df = df[df['chol'] >0]\n",
    "df = df[df['trestbps'] >0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'] = df['target'].astype('category')\n",
    "df['exang'] = df['exang'].astype('category')\n",
    "df['fbs'] = df['fbs'].astype('category')\n",
    "df['cp'] = df['cp'].astype('category')\n",
    "df['restecg'] = df['restecg'].astype('category')\n",
    "df['slope'] = df['slope'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dowhy import gcm\n",
    "causal_model = gcm.InvertibleStructuralCausalModel(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcm.auto.assign_causal_mechanisms(causal_model, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcm.fit(causal_model, df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check model fit statistics\n",
    "print(gcm.evaluate_causal_model(causal_model, df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_high_risk_tp = X_high_risk_tp.assign(target=1)\n",
    "df_high_risk_tp = X_high_risk_tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_high_risk_tp.to_csv(\"df_high_risk_tp.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_high_risk_tp[3:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_high_risk_tp)):\n",
    "    df_risk = df_high_risk_tp.iloc[[i]]\n",
    "    # Apply the filtering conditions\n",
    "    age = df_risk['age']\n",
    "    chol_risk = df_risk['chol']\n",
    "    trestbps_risk = df_risk['trestbps']\n",
    "    print(\"\\nOriginal DataFrame:\")\n",
    "    print(df_risk)\n",
    "    \n",
    "    exp = exps_ideal[i]\n",
    "    if exp[0] is not None:\n",
    "        df_cf = exp[0].cf_examples_list[0].final_cfs_df\n",
    "        \n",
    "        for j in range(len(df_cf)):\n",
    "            cf_chol = df_cf['chol'].iloc[j]\n",
    "            cf_trestbps = df_cf['trestbps'].iloc[j] if 'trestbps' in df_cf.columns else None\n",
    "            \n",
    "            # Check if 'chol' and 'target' are not None\n",
    "            if pd.notna(cf_chol) and df_risk['target'].notna().all():\n",
    "                intervention_dict = {'chol': lambda chol: cf_chol}\n",
    "            elif pd.isna(cf_chol) and pd.notna(cf_trestbps) and df_risk['target'].notna().all():\n",
    "                intervention_dict = {'trestbps': lambda trestbps: cf_trestbps}\n",
    "            else:\n",
    "                print(\"chol or target is None\")\n",
    "                continue\n",
    "\n",
    "            cf_samples = gcm.interventional_samples(causal_model, intervention_dict, observed_data=df_risk)\n",
    "            \n",
    "            cf_samples_filtered = cf_samples[\n",
    "                (cf_samples['chol'] < chol_risk)\n",
    "                 (cf_samples['chol'] < chol_risk)                      \n",
    "            ]\n",
    "            \n",
    "            # Check if any of the target values in filtered cf_samples are 0\n",
    "            if (cf_samples_filtered['target'] == 0).any():\n",
    "                # Filter the counterfactual samples that resulted in target = 0\n",
    "                cf_worked = cf_samples_filtered[cf_samples_filtered['target'] == 0]\n",
    "                for index, row in cf_worked.iterrows():\n",
    "                    print(\"\\nCounterfactual DataFrame:\")\n",
    "                    print(cf_samples_filtered)\n",
    "                    print(\"\\nCholesterol Level:\", row['chol'])\n",
    "                    print(\"Trestbps Level:\", row['trestbps'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''for i in range(len(df_high_risk_tp)):\n",
    "    df_risk = df_high_risk_tp.iloc[[i]]\n",
    "    # Apply the filtering conditions\n",
    "    age = df_risk['age']\n",
    "    chol_risk = df_risk['chol']\n",
    "    thalach_risk = df_risk['thalach']\n",
    "    print(\"\\nOriginal DataFrame:\")\n",
    "    print(df_risk)\n",
    "    \n",
    "    exp = exps_ideal[i]\n",
    "    if exp[0] is not None:\n",
    "        df_cf = exp[0].cf_examples_list[0].final_cfs_df\n",
    "        \n",
    "        for j in range(len(df_cf)):\n",
    "            cf_chol = df_cf['chol'].iloc[j]\n",
    "            cf_thalach = df_cf['thalach'].iloc[j]\n",
    "            \n",
    "            # Check if 'chol' and 'target' are not None\n",
    "            if pd.notna(cf_chol) and pd.notna(cf_thalach) and df_risk['target'].notna().all():\n",
    "                cf_samples = gcm.interventional_samples(causal_model, {'chol': lambda chol: cf_chol, 'thalach': lambda thalach: cf_thalach}, observed_data=df_risk)\n",
    "                cf_samples['exang'] = cf_samples['exang'].clip(0, 1).astype('category')\n",
    "                \n",
    "               \n",
    "                \n",
    "                cf_samples_filtered = cf_samples[\n",
    "                    (cf_samples['chol'] < chol_risk)                     \n",
    "                ]\n",
    "                \n",
    "                # Check if any of the target values in filtered cf_samples are 0\n",
    "                if (cf_samples_filtered['target'] == 0).any():\n",
    "                    # Filter the counterfactual samples that resulted in target = 0\n",
    "                    cf_worked = cf_samples_filtered[cf_samples_filtered['target'] == 0]\n",
    "                    for index, row in cf_worked.iterrows():\n",
    "                        print(\"\\nCounterfactual DataFrame:\")\n",
    "                        print(cf_samples_filtered)\n",
    "                        print(\"\\nCholesterol Level:\", row['chol'])\n",
    "                        print(\"Thalach Level:\", row['thalach'])\n",
    "            else:\n",
    "                print(\"chol or target is None\")'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_high_risk_tp)):\n",
    "    df_risk = df_high_risk_tp.iloc[[i]]\n",
    "    # Apply the filtering conditions\n",
    "    age = df_risk['age']\n",
    "    chol_risk = df_risk['chol']\n",
    "    thalach_risk = df_risk['thalach']\n",
    "    print(\"\\nOriginal DataFrame:\")\n",
    "    print(df_risk)\n",
    "    \n",
    "    exp = exps_feasible[i]\n",
    "    if exp[0] is not None:\n",
    "        df_cf = exp[0].cf_examples_list[0].final_cfs_df\n",
    "        \n",
    "        for j in range(len(df_cf)):\n",
    "            cf_chol = df_cf['chol'].iloc[j]\n",
    "            cf_thalach = df_cf['thalach'].iloc[j]\n",
    "            \n",
    "            # Check if 'chol' and 'target' are not None\n",
    "            if pd.notna(cf_chol) and pd.notna(cf_thalach) and df_risk['target'].notna().all():\n",
    "                cf_samples = gcm.interventional_samples(causal_model, {'chol': lambda chol: cf_chol, 'thalach': lambda thalach: cf_thalach}, observed_data=df_risk)\n",
    "                cf_samples['exang'] = cf_samples['exang'].clip(0, 1).astype('category')\n",
    "                \n",
    "               \n",
    "                \n",
    "                cf_samples_filtered = cf_samples[\n",
    "                    (cf_samples['chol'] < chol_risk) &\n",
    "                    (cf_samples['thalach'] > thalach_risk) &\n",
    "                    (cf_samples['thalach'] < (220 - age))\n",
    "                ]\n",
    "                \n",
    "                # Check if any of the target values in filtered cf_samples are 0\n",
    "                if (cf_samples_filtered['target'] == 0).any():\n",
    "                    # Filter the counterfactual samples that resulted in target = 0\n",
    "                    cf_worked = cf_samples_filtered[cf_samples_filtered['target'] == 0]\n",
    "                    for index, row in cf_worked.iterrows():\n",
    "                        print(\"\\nCounterfactual DataFrame:\")\n",
    "                        print(cf_samples_filtered)\n",
    "                        print(\"\\nCholesterol Level:\", row['chol'])\n",
    "                        print(\"Thalach Level:\", row['thalach'])\n",
    "            else:\n",
    "                print(\"chol or target is None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_high_risk_tp)):\n",
    "    df_risk = df_high_risk_tp.iloc[[i]]\n",
    "    # Apply the filtering conditions\n",
    "    age = df_risk['age']\n",
    "    chol_risk = df_risk['chol']\n",
    "    thalach_risk = df_risk['thalach']\n",
    "    print(\"\\nOriginal DataFrame:\")\n",
    "    print(df_risk)\n",
    "    \n",
    "    exp = exps_feasible_[i]\n",
    "    if exp[0] is not None:\n",
    "        df_cf = exp[0].cf_examples_list[0].final_cfs_df\n",
    "        \n",
    "        for j in range(len(df_cf)):\n",
    "            cf_chol = df_cf['chol'].iloc[j]\n",
    "            cf_thalach = df_cf['thalach'].iloc[j]\n",
    "            \n",
    "            # Check if 'chol' and 'target' are not None\n",
    "            if pd.notna(cf_chol) and pd.notna(cf_thalach) and df_risk['target'].notna().all():\n",
    "                cf_samples = gcm.interventional_samples(causal_model, {'chol': lambda chol: cf_chol, 'thalach': lambda thalach: cf_thalach}, observed_data=df_risk)\n",
    "                cf_samples['exang'] = cf_samples['exang'].clip(0, 1).astype('category')\n",
    "                \n",
    "               \n",
    "                \n",
    "                cf_samples_filtered = cf_samples[\n",
    "                    (cf_samples['chol'] < chol_risk) &\n",
    "                    (cf_samples['thalach'] > thalach_risk) &\n",
    "                    (cf_samples['thalach'] < (220 - age))\n",
    "                ]\n",
    "                \n",
    "                # Check if any of the target values in filtered cf_samples are 0\n",
    "                if (cf_samples_filtered['target'] == 0).any():\n",
    "                    # Filter the counterfactual samples that resulted in target = 0\n",
    "                    cf_worked = cf_samples_filtered[cf_samples_filtered['target'] == 0]\n",
    "                    for index, row in cf_worked.iterrows():\n",
    "                        print(\"\\nCounterfactual DataFrame:\")\n",
    "                        print(cf_samples_filtered)\n",
    "                        print(\"\\nCholesterol Level:\", row['chol'])\n",
    "                        print(\"Thalach Level:\", row['thalach'])\n",
    "            else:\n",
    "                print(\"chol or target is None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_high_risk_tp)):\n",
    "    df_risk = df_high_risk_tp.iloc[[i]]\n",
    "    print(\"\\nOriginal DataFrame:\")\n",
    "    print(df_risk)\n",
    "    \n",
    "    exp = exps_ideal[i]\n",
    "    if exp[0] is not None:\n",
    "        df_cf = exp[0].cf_examples_list[0].final_cfs_df\n",
    "        \n",
    "        for j in range(len(df_cf)):\n",
    "            cf_chol = df_cf['chol'].iloc[j]\n",
    "            cf_thalach = df_cf['thalach'].iloc[j]\n",
    "            \n",
    "            # Check if 'chol' and 'target' are not None\n",
    "            if pd.notna(cf_chol) and pd.notna(cf_thalach) and df_risk['target'].notna().all():\n",
    "                cf_samples = gcm.interventional_samples(causal_model, {'chol': lambda chol: cf_chol, 'thalach': lambda thalach: cf_thalach}, observed_data=df_risk)\n",
    "                cf_samples['exang'] = cf_samples['exang'].clip(0, 1).astype('category')\n",
    "                \n",
    "                # Check if any of the target values in cf_samples are 0\n",
    "                if (cf_samples['target'] == 0).any():\n",
    "                    # Filter the counterfactual samples that resulted in target = 0\n",
    "                    cf_worked = cf_samples[cf_samples['target'] == 0]\n",
    "                    for index, row in cf_worked.iterrows():\n",
    "                        print(\"\\nCounterfactual DataFrame:\")\n",
    "                        print(cf_samples)\n",
    "                        print(\"\\nCholesterol Level:\", row['chol'])\n",
    "                        print(\"Thalach Level:\", row['thalach'])\n",
    "            else:\n",
    "                print(\"chol or target is None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_high_risk_tp[3:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "samples_chol = gcm.interventional_samples(causal_model, {'chol': lambda chol:208,'thalach': lambda thalach:159}, observed_data=df_high_risk_tp[3:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_high_risk_tp[3:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_chol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples['exang'] = samples['exang'].clip(0, 1).astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure both DataFrames have the same index\n",
    "df_risk = df_risk.reset_index(drop=True)\n",
    "samples = samples.reset_index(drop=True)\n",
    "\n",
    "# Find rows where exang has changed from 1 to 0\n",
    "changed_rows = df_risk[(df_risk['exang'] == 1) & (samples['exang'] == 0)]\n",
    "\n",
    "# Display the rows\n",
    "print(changed_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(samples['target'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_chol"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mtech-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
